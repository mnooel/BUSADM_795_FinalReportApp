<!-- analysis_plan.data_exploration1 -->
<div class="html_content">
    <h3>Model Building</h3>
    <p>
        Our exploratory analysis indicated that our independent variables have linear relationships to income. The
        strength of the linear relationship varied but we feel it is reasonable to use linear regression. Given that we
        are analyzing a time series we decided to use lagging predictor variables in our analysis as well as indicator
        variables for each month of the year. The indicator variables will help account for seasonality in the time
        series.
    </p>
    <h3>Modeling Technique</h3>
    <p>
        We will use three models to predict monthly income at Core Creative. The models to be used are two linear
        regression models and a neural network. For the first linear regression we will use a single lagging predictor
        variable and indicator variables for each month of the year. The second linear regression will introduce several
        additional lagging variables that are selected based on best subsets analysis. The neural network model will use
        the same variables as the second linear regression model. Below is an overview of the modeling techniques we
        selected.
    </p>
    <h3>Linear Regression</h3>
    <p>
        The assumptions of linear regression include:
    </p>
    <ol>
        <li>Linear relationship: It is assumed that a linear relationship exists between the dependent and independent
            variables.
        </li>
        <li>Independence: There is no correlation between consecutive residuals in time series data.</li>
        <li>Homoscedasticity: The residuals have constant variance at every level of x.</li>
        <li>Normality: The residuals of the model are normally distributed.</li>
    </ol>
    <h3>Neural Network</h3>
    <p>
        We wanted to try one more modeling technique on the Core Creative data that was not based on linear regression.
        The technique we chose is the popular machine learning practice of artificial neural networks. The specific type
        of neural network we use is called a feed-forward neural network. This neural network passes data from inputs,
        through layers of nodes, to outputs in one direction. Each node receives the weighted sum of the input nodes
        feeding into it. If the value of this node is above a certain threshold, it “fires” by sending its value to the
        next node.
    </p>
    <p>
        The neural network is improved with the use of training data. Before being trained, the neural network’s weights
        and thresholds are random values. As the training data passes through the network, these values are adjusted.
        After training and testing the model through an iterative process, the neural network can be used to predict
        outcomes using new data <a href="https://statswithr.github.io/book/bayesian-model-choice.html" target="_blank">
                (Hardesty, 2017)
            </a>.
    </p>
    <p>
        Our implementation of a neural network will rely on the ‘neuralnet’ package in R. We will use the same dataset
        as the linear regression models and compare the results of the neural network to the linear models.
    </p>
</div>